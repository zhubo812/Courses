## 第五章 自动分词与词性标注
~~~~
### 主要内容
1. 问题的提出
2. 自动分词的概念
3. 自动分词规范
4. 自动分词的基本方法
5. 汉语自动分词的基本原则
6. 分词歧义
7. 未登录词
8. 汉语分词基本算法
9. 词性标注
~~~~
### 5.1 问题的提出
~~~~
<font color = yellow>巧</font>

灵<font color = yellow>巧</font>

<font color = yellow>巧</font>克力  



~~~~
#### 中文分词示例
- 中国经济发展很快
- 中国/  经济/  发展/  很/  快
~~~~
### 5.2 自动分词的概念
- 词是自然语言中能够独立运用的最小单位，是自然语言处理的基本单位。
- 汉语文本是基于单字的，汉语的书面表达方式也是以汉字作为最小单位的，词与词之间没有显性的界限标志，因此分词是汉语文本分析处理中首先要解决的问题。
~~~~
#### 定义
让计算机把语流串自动变成以词为单位的形式就是汉语的自动分词技术。

~~~~
### 5.3 自动分词的规范
~~~~
- 《信息处理用汉语分词规范》GB/T13715-92，中国标准出版社，1993
- 《资讯处理用中文分词规范》台湾中研院，1995
~~~~
#### 《信息处理用汉语分词规范》GB/T13715-92，中国标准出版社，1993
1. 分词单位：汉语信息处理使用的、具有确定的语义或语法功能的基本单位。包括本规范的规则限定的词和词组。
1. 规范按词类分别给出了各类分词单位的定义，并给出例子。
1. 规范中多处使用了“结合紧密、使用稳定”的表述
1. 不但有规范还要有词表（还要有语料）
1. 什么是切分单位和应用有关
1. 工程观点
~~~~
#### 《资讯处理用中文分词规范》台湾中研院，1995
汉语分词规范问题分词规范直接影响到词表和分词语料库的质量，虽然已经有了国家标准（《信息处理用限定汉语分词规范（GB13715）》），有的单位也制定了自己的规范，但这些规范的可操作性都不太强，很难构造出一致性好的词表和分词语料库来。对汉语中什么是词，有两个不清的界限：单字词与语素（词素）、词与短语。如，花草，湖边，房顶，鸭蛋，小鸟，担水，一层，翻过等 。
~~~~

#### 自动分词面临的困难
1. 理论上：  
	- 什么是词，什么不是词？  
		- 张经理、牛肉、五分之三
2. 技术上：  
	- 歧义切分  
	- 未登录词处理
~~~~

### 5.4 汉语自动分词的原则
1. 汉语自动分词的基本原则
2. 汉语自动分词的辅助原则
3. 具体的分词标准实例
4. 常见的动词分词规范

~~~~
#### 5.4.1 汉语自动分词的基本原则
~~~~
1. 语义上无法由组合成分直接相加而得到的字串应该合并为一个分词单位。（合并原则）
~~~~
- 示例
	- 不管三七二十一（成语）  
	- 或多或少（副词片语）  
	- 十三点（定量结构）  
	- 六月（定名结构）  
	- 谈谈（重叠结构，表示尝试）  
	- 辛辛苦苦（重叠结构，加强程度）  
	- 进出口（合并结构）  
~~~~
2. 语类无法由组合成分直接得到的字串应该合并为一个分词单位。（合并原则）
~~~~
- 示例
	- 字串的语法功能不符合组合规律，如：好吃，好喝，好听，好看等。  
	- 字串的内部结构不符合语法规律，如：游水等。
~~~~

#### 5.4.2 汉语自动分词的辅助原则

<font color = yellow>辅助原则为操作性原则，不是绝对的。</font>
~~~~
1. 有明显分隔符标记的应该切分，分隔标记指标点符号或一个词（切分原则）。
~~~~
- 示例
	- 上、下课  
	- 上/、/下课  
	- 洗了个澡  
	- 洗/ 了/ 个/ 澡
~~~~

2. 附着性语（词）素和前后词合并为一个分词单位（合并原则）。
~~~~
示例  
- “吝”是一个附着语素，“不吝”“吝于”等合并成一个词；  
- “员”：检查员、邮递员、技术员等；  
- “化”：现代化、合理化、多变化、民营化等。  
~~~~

3. 使用频率高或共现率高的字串尽量合并为一个分词单位（合并原则）。
~~~~
- 示例  
	- “进出”“收放”（动词并列）；  
	- “大笑”“改称”（动词偏正）；  
	- “关门”“洗衣”“卸货”（动宾） ；  
	- “春夏秋冬”“轻重缓急”“男女”（并列）；  
	- “象牙”（名词偏正）；  
	- “暂不”“毫不”“不再”“早已”（副词并列）等
~~~~
4. 双音节加单音节的偏正式名词尽量合并为一个分词单位（合并原则）。
~~~~
- 示例  
	- “线、权、车、点”等所构成的偏正式名词; 
	- “国际线、分数线、贫困线”;  
	- “领导权、发言权”;  
	- “垃圾车、交通车、午餐车”;  
	- “立足点、共同点、着眼点”等。
~~~~
5. 双音节结构的偏正式动词应尽量合并为一个分词单位（合并原则）
~~~~
- 示例
	- 本原则只适合少数偏正式动词：  
	- “紧追其后”“组建完成”等,不适合动宾及主谓式复合动词。
~~~~
6. 内部结构复杂、合并起来过于冗长的词尽量切分（切分原则）
~~~~
- 示例 
	- 词组带接尾词：太空/ 计划/ 室、塑料/ 制品/ 业  
	- 动词带双音节结果补语：看/ 清楚、讨论/ 完毕  
	- 复杂结构：自来水/ 公司、中文/ 分词/ 规范/ 研究/ 计划  
	- 正反问句：喜欢/ 不/ 喜欢、参加/ 不/ 参加  
~~~~
	- 动宾结构、述补结构的动词带词缀时：写信/ 给、取出/ 给、穿衣/ 去  
	- 词组或句子的专名，多见于书面语，戏剧名、歌曲名等：鲸鱼/ 的/ 生/ 与/ 死、那/ 一/ 年/ 我们/ 都/ 很/ 酷。  

	- 专名带普通名词：胡/ 先生、京沪/ 铁路。
~~~~
#### 5.4.3 具体的分词标准实例
~~~~
1. 结合紧密、使用稳定的二字或三字词

- 示例  
	- 发展、可爱、红旗、对不起、自行车、青霉素 

2. 四字成语一律为分词单位，四字词或结合紧密、使用稳定的四字词组

- 示例  
	- 胸有成竹，欣欣向荣  
	- 社会主义、春夏秋冬、由此可见
~~~~
3. 五字和五字以上的谚语、格言等，分开后如不违背原有组合的意义，应予切分

- 示例 
	- 时间/就/是/生命/
	- 失败/是/成功/之/母
~~~~
4. 结合紧密、使用稳定的词组则不予切分

- 示例  
	- 不管三七二十一
~~~~
5. 惯用语和有转义的词或词组，在转义的语言环境下，一律为分词单位

- 示例   
	- 妇女能顶/半边天/  
	- 他真小气，象个/铁公鸡/ 
~~~~
6. 略语一律为分词单位组

- 示例  
	- 科技、奥运会、工农业 
~~~~
7. 分词单位加形成儿化音的“儿”

- 示例   
	- 花儿，悄悄儿，玩儿
~~~~
8. 阿拉伯数字等，仍保留原有形式

- 示例  
	- 123，3.14，-0.1
~~~~
9. 现代汉语中其它语言的汉字音译外来词，不切分

- 示例  
	- 巧克力，吉普 
~~~~
10. 不同的语言环境中的同形异构现象，按照具体语言环境的语义进行切分
 
- 示例   
	- 把/手/抬起来
	- 这个/把手/是木制的  
~~~~
#### 5.4.4 常见的动词分词规范
~~~~
1.动词前的否定副词一律单独切分
- 示例   
	- 不/写
	- 不/能
	- 没/研究
	- 未/完成

~~~~
2. 用肯定加否定的形式表示疑问的动词词组一律切分，不完整的则不予切分

- 示例  
	- 说/没/说  
	- 看/不/看  
	- 相信/不/相信
~~~~
3. 动宾结构的词或结合紧密、使用稳定的

- 示例   
	- 开会  
	- 跳舞  
	- 解决/吃饭/问题  
	- 孩子该/念书/了   
~~~~
4. 结合不紧密或有众多与之相同结构词组的动宾词组一律切分

- 示例   
	- 吃/鱼    
	- 学/滑冰  
	- 写/报告
~~~~
5. 动宾结构的词或词组如中间插入其它成分，则应予切分

- 示例  
	- 吃/两/顿/饭   
	- 跳/新疆/舞  
~~~~
6. 动补结构的二字词或结合紧密、使用稳定的二字动补词组，不予切分

- 示例   
	- 打倒
	- 提高
	- 加长
	- 做好
~~~~
7. “2十1”或“1十2”结构的动补词组一律切分

- 示例   
	- 整理/好  
	- 说/清楚  
	- 解释/清楚  
	- 打/得/倒  
	- 提/不/高
~~~~
8. 偏正结构的词，以及结合紧密的词不予切分

- 示例  
	- 胡闹
	- 瞎说
	- 死记 
~~~~
9. 复合趋向动词一律为分词单位

- 示例   
	- 出去
	- 进来  

- 当插入“得、不”时应予切分
	- 出/得/去  
	- 进/不/来
~~~~
10.动词与趋向动词结合的词组一律切分

- 示例   
	- 寄/来  
	- 跑/出去
~~~~
11.多字动词无连词并列，一律切分

- 示例   
	- 调查/研究   
	- 宣传/鼓动
~~~~
### 5.6 分词歧义

1. 交集型切分歧义
2. 组合型切分歧义
3. “真歧义”和“伪歧义”
~~~~

切分歧义是汉语自动分词研究中的一个“拦路虎”。梁南元（1987）最早对这个现象进行了比较系统的考察。他定义了两种基本的切分歧义类型： 
1. 交集型切分歧义
2. 组合型切分歧义
~~~~
#### 5.6.1 交集型歧义
汉字串AJB被称作交集型切分歧义，如果满足AJ、JB同时为词(A、J、B分别为汉字串)。此时汉字串J被称作交集串。

- 示例  
	- “结合成分子”  
	- 结合 | 成 分|子 |  
	- 结合|成|分子|  
	- 结 | 合成 |分子|  
	- 其中A＝“结”，J＝“合”，B＝“成”。 
~~~~
- 示例  
	- 美国会通过对台售武法案  
	- 乒乓球拍卖完了  
	- 大学生  
	- 研究生物  
	- 从小学起  
	- 为人民工作  
	- 中国产品质量  
	- 部分居民生活水平  
~~~~

##### 交集型歧义链长 
一个交集型切分歧义所拥有的交集串的集合称为交集串链，它的个数称为链长。
- 示例   
	- “结合成分子”   
	- 交集型切分歧义“结合成分子”、“结合”、“合成”、“成分”、“分子”均成词，交集串的集合为｛“合”，“成”，“分”｝，链长为3。 
~~~~
- 链长示例  
	- 从小学，{小}，歧义字段的链长为1；  
	- 结合成分，{合，成}，歧义字段的链长为2；  
	- 为人民工作，{人，民，工}，歧义字段的链长为3；  
	- 中国产品质量，{国，产，品，质}，歧义字段的链长为4；  
	- 部分居民生活水平  {分，居，民，生，活，水}，链长为6。  
	- 治理解放大道路面积水  {理，解，放，大，道，路，面，积}，链长为8。

~~~~

#### 5.6.2 组合型歧义
汉字串AB被称作组合型切分歧义，如果满足条件：A、B、AB同时为词。

- 示例“起身”
	- 他站 | 起 | 身 | 来。  
	- 他明天 | 起身 | 去北京。 
- 示例“把手”  
	- 门 | 把| 手| 弄坏了 。  
	- 门 | 把手| 弄坏了 。  
~~~~
#### 5.6.3 “真歧义”和“伪歧义”
1. 真歧义
歧义字段在不同的语境中确实有多种切分形式。
~~~~
- 示例“地面积”  
	- 这块/地/面积/还真不小
	- 地面/积/了厚厚的雪
~~~~
- 示例“中国有”  
	- 必须加强企业/中/国有/资产的管理
	- 中国/有/能力修建跨海大桥
~~~~
2. 伪歧义
歧义字段单独拿出来看有歧义，但在(所有)真实语境中仅有一种切分形式可接受。
~~~~
- 示例“挨批评”  
	- 挨/批评(√) 挨批/评(×)  
	- 学生/挨/批评/挥拳打老师

- 示例“平淡”  
	- 平淡(√) 平/淡(×)  
	- 平淡/生活感动人
~~~~

### 5.7 未登录词
一般情况下，词典都能覆盖大多数的词语，但有相当一部分的词语不可能穷尽地收入系统词典中，这些词语称为<font color=yellow>未登录词</font>或<font color=yellow>新词</font>。
~~~~
#### 5.7.1 未登录词分类
1. 专有名词：中文人名、地名、机构名称、外国译名、时间词：2018年1月1日
2. 重叠词：“高高兴兴”“研究研究” 
3. 派生词：“一次性用品” 
4. 新出现的词汇、术语、个别俗语等。例如：微信、微博、禽流感等。
~~~~

### 5.8 自动分词的基本方法
- 有词典切分/无词典切分
- 基于规则分析方法/基于统计方法

~~~~
#### 自动分词的基本方法有两种：  
1. 基于规则；  
2. 基于统计；
~~~~
1.1 机械切分，机械切分是指运用简单的模式匹配技术的无条件切分；  
1.2 智能切分，智能切分是指模拟人的思维，采用词 法、句法、语义及语用等各种知识进行条件切分。
~~~~
- 简单的模式匹配：正向最大匹配、逆向最大匹配法、双向匹配法
- 基于规则的方法：最少分词算法
- 基于统计的方法：统计语言模型分词、串频统计和词形匹配相结合的汉语自动分词、无词典分词
~~~~

####  5.8.1 汉语自动分词的一般步骤
1. 词语粗分
	- 最大匹配
	- 最短路径
	- 概率统计模型
	- 全切分
2. 词语细分
	- 歧义排除
	- 未登录识别
3. 词性标注
~~~~
1. 正向最大匹配分词
2. 逆向最大匹配分词
3. 双向匹配法
4. 全切分方法
5. 最短路径法
6. 最大概率法分词
7. 基于统计语言模型的分词方法
8. 基于HMM的分词方法
9. 基于统计的分词与词性标注一体化方法
10. 由字构词的(基于字标注)分词方法


~~~~
#### 5.8.2 正向最大匹配分词
Forward Maximum Matching method, FMM算法描述：  
句子：`$S=c_1c_2...c_n$`
假设词：`$w_i=c_1c_2...c_m$`为词典中最长词的字数  
1. 令`$i=0$`，当前指针`$p_i$`指向输入字串的初始位置，执行下面的操作：
2. 计算当前指针`$p_i$`到字串末端的字数（即未被切分字串的长度）`$n$`，如果`$n=1$`，转3。否则，令m=词典中最长单词的字数，如果`$n<m,m=n$`；
3. 从当前指针`$p_i$`起取`$m$`个汉字作为词`$w_i$`，作如下判断：  
~~~~
3.1 如果`$w_i$`确实是词典中的词，则在`$w_i$`后添加一个切分标志，转3.3；  
3.2 如果`$w_i$`不是词典中的词且`$w_i$`的长度大于1，将`$w_i$`从右端去掉一个字，转3.1步；否则（即`$w_i$`的长度等于1），则在`$w_i$`后添加一个切分标志，将`$w_i$`作为单字词添加到词典中，执行3.3；  

3.3 根据`$w_i$`的长度修改指针`$p_i$`的位置，如果`$p_i$`指向字串末端，转4，否则，`$i=i+1$`，返回2）；
~~~~
4. 输出切分结果，结束分词程序
~~~~
- 正向最大匹配分词示例
	1. 设词典中最长单词的字数为7  
	2. 输入字串：他是研究生物化学的  
	3. 切分过程：  
		- <font color = yellow>他是研究生物化</font>学的  
		- <font color = yellow>他是研究生物</font>化学的  
		- <font color = yellow>他是研究生</font>物化学的  
 
- FMM切分结果：他||是||研究生||物化||学||的||。  

~~~~

#### 5.8.3 逆向最大匹配分词

Backward Maximum Matching method, 又称为Reverse Maximum Matching, 简称 RMM 方法  
~~~~
##### BMM算法描述：  
分词过程与FMM方法相同，不过是从句子(或文章)末尾开始处理，每次匹配不成功时去掉的是前面的一个汉字。
~~~~

逆向最大匹配分词示例

- 设词典中最长单词的字数为7  
- 输入字串：他是研究生物化学的  
- BMM切分结果：他||是||研究||生物||化学||的||。
~~~~
实验表明：逆向最大匹配法比最大匹配法更有效，错误切分率为`$\frac{1}{245}$`
~~~~
#### 5.8.4 双向匹配法
Bi-direction Matching Method, BMM  
比较FMM法与BMM法的切分结果，从而决定正确的切分可以识别出分词中的交叉歧义
~~~~

##### 算法评价

优点：程序简单易行，开发周期短；仅需要很少的语言资源（词表），不需要任何词法、句法、语义资源；

~~~~
弱点：切分歧义消解的能力差；切分正确率不高，一般在95％左右(见《汉语分词技术综述 》) 。
- 错误切分率为1/169（梁南元的统计）。
- 往往不单独使用，而是与其它方法配合使用
~~~~

#### 5.8.5 全切分方法
依据词表，给出输入文本的所有可能的切分结果
~~~~

- 输入: 提高人民生活水平  
- 输出:   
	- 提/高/人/民/生/活/水/平  
	- 提高/人/民/生/活/水/平  
	- 提高/人民/生/活/水/平  
	- 提高/人民/生活/水/平  
	- 提高/人民/生活/水平  
	-  ……  
~~~~
依据一定的原则选择一种结果作为最终切分结果。例如：
- 选择词数最少的切分结果(最短路径)
- 选择概率最大的切分结果
~~~~

#### 5.8.6 最短路径法 
基本思想：设待分字串`$S=c_1c_2...c_n$`，其中，`$c_i(i=1,2,...n)$`为单个的字,`$n$`为串的长度，`$n\geq1$`。建立一个节点数为`$n+1$`的切分有向无环图`$G$`各节点编号依次为`$V_0,V_1,V_2...V_n$`
~~~~
![nsp](../cl/img/nsp.png)

求N-最短路径：贪心法(如Dijkstra算法)。
~~~~
##### 最短路径算法 
1. 相邻节点`$v_{k-1}, v_k$`之间建立有向边`$<v_{k-1}, v_k>$`，边对应的词默认为`$c_k(k =1, 2, …, n)$`。
2. 如果`$w= c_ic_{i+1}...c_j (0<i<j\le n)$` 是一个词，则节点`$v_{i-1}, v_j$` 之间建立有向边`$<v_{i-1},v_j>$`，边对应的词为`$w$`。
3. 重复上述步骤(2)，直到没有新的路径（词序列）产生。
4. 从产生的所有路径中，选择路径最短的（词数最少的）作为最终分词结果。
~~~~
- 输入: 他只会诊断一般的疾病。  
- 输出:   
	- 他||只会||诊断||一般||的||疾病。(6个词)  
	- 他||只||会诊||断||一般||的||疾病。(7个词)  
	- ……  
	- 最终结果：他||只会||诊断||一般||的||疾病。
~~~~
- 输入: 他说的确实在理。  
- 输出:   
	- 他||说||的||确实||在理。(5个词)  
	- 他||说||的确||实在||理。(5个词)  
	- ……  
~~~~
- 输入: 北京大学生体育馆。  
- 输出:   
	- 北京大学||生||体育馆。(3个词)  
	- 北京||大学生||体育馆。(3个词)  
	- ……  
~~~~
##### 算法评价
1. 优点：
- 采用的原则（切分出来的词数最少）符合汉语自身规律。
- 需要的语言资源（词表）也不多。
~~~~
2. 弱点：  
- 对许多歧义字段难以区分，最短路径有多条时，选择最终的输出结果缺乏应有的标准。
- 字串长度较大和选取的最短路径数增大时，长度相同的路径数急剧增加，选择最终正确的结果困难越来越越大。
~~~~

#### 5.8.7 最大概率法分词
~~~~
##### 基本思想：
1. 一个待切分的汉字串可能包含多种分词结果
2. 将其中概率最大的那个作为该字串的分词结果
~~~~
  
- 输入: `$S$`:有意见分歧。  
- 输出:  
	- `$w_1$`:有/  意见/  分歧/ 。  
	- `$w_1$`:有意/  见/  分歧/ 。  
	- `$\max(P(w_1|S),P(w_2|S))?$`
~~~~
$$
\arg \max P(W|S)=\arg \max \frac{P(S|W)\times P(W)}{P(S)}=\arg \max P(W)
$$

$$
P(W)=P(w_1,w_2,...,w_i)\approx P(w_1)\times P(w_2)\times ...\times P(w_i)
$$

$$
P(w_i)=\frac{n}{N} 
$$
其中,`$n$`表示词`$w_i$`在语料库中的出现的词数,`$N$`表示语料库中的总词数。
~~~~

词语 | 概率
---|---
... | ...
有 | 0.0180
有意 | 0.0005
意见 | 0.0010
见 | 0.0002
分歧 | 0.0001
... | ...
~~~~
- `$P(w_1)=P($`有`$)\times P($`意见`$)\times P($`分歧`$)=1.8\times 10^{-9}$`  
- `$P(w_2)=P($`有意`$)\times P($`见`$)\times P($`分歧`$)=1\times 10^{-11}$`  
- `$P(w_1)>P(w_2)$`

~~~~
##### 提高计算效率
如何尽快找到概率最大的词串（路径）？
~~~~

##### 计算累计概率
- `$P'(w_i)=P'(w_{i-1})\times P(w_i)$`,
- `$P'(w_i)$`为到达候选词`$w_i$`时的累计概率
- `$P'($`意见`$)=P($`有`$)\times P($`意见`$)$`
- `$P'($`有`$)=P($`有`$)$`
~~~~

##### 左邻词
假定对字串从左到右进行扫描，可以得到 `$w_1,w_2,...,w_i,w_{i-1},…$`等若干候选词，如果`$w_{i-1}$`的尾字跟`$wi$` 的首字邻接，就称`$w_{i-1}$`为`$wi$`的左邻词。  
比如上面例中，候选词“有”就是候选词“意见”的左邻词，“意见”和“见”都是“分歧”的左邻词。字串最左边的词没有左邻词。
~~~~

##### 最佳左邻词
如果某个候选词`$w_i$`有若干个左邻词`$w_j,w_k,…$` 等等，其中累计概率最大的候选词称为wi的最佳左邻词。比如候选词“意见”只有一个左邻词“有”，因此,“有”同时也就是“意见”的最佳左邻词；候选词“分歧”有两个左邻词“意见”和“见”，其中“意见”的累计概率大于“见”累计概率，因此“意见”是“分歧”的最佳左邻词
~~~~
##### 算法描述
1. 对一个待分词的字串`$S$`,按照从左到右的顺序取出全部候选词`$w_1,w_2,...,w_i,...,w_n$` ；
2. 到词典中查出每个候选词 的概率值`$P(wi)$`,并记录每个候选词的全部左邻词；
3. 按照`$P'(w_i)=P'(w_{i-1})\times P(w_i)$`计算每个候选词的累计概率，同时比较得到每个候选词的最佳左邻词；
4. 如果当前词`$w_n$`是字串`$S$`的尾词，且累计概率`$P'(w_n)$` 最大，则`$w_n$` 就是`$S$`的终点词；
5. 从`$w_n$`开始，按照从右到左顺序，依次将每个词的最佳左邻词输出，即为`$S$`的分词结果。
~~~~

##### 最大概率分词算法示例
1. 对“有意见分歧”，从左到右进行一遍扫描，得到全部候选词：“有”“有意”“意见”“见”“分歧”；
2. 对每个候选词，记录下它的概率值，并将累计概率赋初值为0；
~~~~
3. 顺次计算各个候选词的累计概率值，同时记录每个候选词的最佳左邻词:  
	- `$P'($`有`$)=P($`有`$)$`  
	- `$P'($`有意`$)=P($`有意`$)$`  
	- `$P'($`意见`$)=P($`有`$)\times P($`意见`$)$`(“意见”的最佳左邻词为“有”)  
	- `$P'($`见`$)=P($`有意`$)\times P($`见`$)$`(“见”的最佳左邻词为“有意”)  
	- `$P'($`意见`$)>P($`见`$)$` 
~~~~
4. “分歧”是尾词，“意见”是“分歧”的最佳左邻词，分词过程结束  
  
- 输出结果：有/  意见/   分歧/
~~~~

##### 最大概率法分词的问题
1. 并不能解决所有的交集型歧义问题
~~~~
- 示例“这事的确定不下来”  
	- `$w_1=$`这/事/的确/定/不/下来/  
	- `$w_2=$`这/事/的/确定/不/下来/  
~~~~
2. 无法解决组合型歧义问题

- 示例“做完作业才能看电视”  
	- `$w_1=$`做/完/作业/才能/看/电视/  
	- `$w_2=$`做/完/作业/才/能/看/电视/ 
~~~~

#### 5.8.8 基于统计语言模型的分词方法
~~~~
##### 算法描述
设对于待切分的句子`$S$`,`$W=w_1w_2...w_k,(1\leq k \leq n)$`是一种可能的切分。
~~~~
微软研究院把一个可能的词序列`$W$`转换成一个可能的词类序列`$C=c_1c_2c_n$`，即：
- 专有名词的人名PN、地名LN、机构名ON分别作为一类；
- 实体名词中的日期dat、时间tim、百分数per、货币mon等作为一类，简称为实体名；
- 对词法派生词MW和词表词LW，每个词单独作为一类。
~~~~
那么有公式(1)：

$$
C={\operatorname{argmax}} P(C)P(S|C)
$$

其中,`$P(C)$`为语言模型,`$P(S|C)$`生成模型。`$P(C)$`可采用3元语法，可以用公式(2)表示为：
$$
P(C)=P(c_1)P(c_2|c_1)\prod_{i=3}^NP(c_i|c_{i-2}c_{i-1})
$$
~~~~
生成模型在满足独立性假设的条件下，可近似为公式(3):
$$
P(S|C)\approx \prod_{i=1}^NP(s_i|c_i)
$$
该公式的含意是，任意一个词类生成汉字串的概率只与自身有关，而与其上下文无关。
~~~~
  
- 如果“教授”是词表里的词，那么  
- `$P(s_i=$`教授`$|c_i=LW)=1$`  
- 每个词表词`$LW$`单独作为一类
~~~~
##### 表1 生成模型`$P(S|C)$`

词类 | 生成模型`$P(S\|C)$` | 语言知识
---|---|---
词表词(LW) | 若`$S$`是词表词,`$P(S\|C)=1$`,否则为0 | 分词词表
词法派生词(MW) | 若`$S$`是派生词,`$P(S\|MW)=1$`,否则为0 | 派生词词表
人名(PN) | 基于字的二元模型 | 姓氏表,中文人名模板
地名(LN) | 基于字的二元模型 | 地名表、地名关键词表、地名简称表
机构名(ON) | 基于词类的二元模型 | 机构名关键词表、机构名简称表
实体名(FT) | 若`$S$`可用实体名规则集`$G$`识别,`$P(S\|G)=1$`,否则为0 | 实体名规则集
~~~~
##### 模型训练步骤
1. 在词表和派生词表的基础上，用正向最大匹配法切分训练语料，专有名词通过一个专门模块标注，实体名词通过相应的规则和有限状态自动机标注，由此产生一个带词类别标记的初始语料；
2. 用带词类别标记的初始语料，采用最大似然估计方法估计语言模型的概率参数；
3. 用语言模型（公式(1)、(2)、(3)），对训练语料重新切分和标注，得到新的训练语料；
4. 重复(2)(3)步，直到系统的性能不再有明显的变化。

~~~~
##### 算法评价

- 优点
	- 减少了很多手工标注的工作
	- 在训练语料规模足够大和覆盖领域足够多时，可以获得较高的切分正确率

- 缺点
	- 训练语料的规模和覆盖领域不好把握
	- 计算量较大

~~~~

#### 5.8.9 基于HMM的分词方法
~~~~
##### 基本思想
把输入字串(句子)`$S$`作为HMM的输入；(切分后的)单词串`$S_w=w_1w_2...w_n (n\geq1)$`为状态的输出，即观察序列；词性序列`$S_c$` 为状态序列，每个词性标记对应HMM中的一个状态`$q_i$`,`$S_c =c_1c_2...c_n$` 。   
利用HMM处理分词问题恰好对应于HMM的三个基本问题。
~~~~
##### 模型步骤
1. 估计HMM模型参数，构造模型`$\mu =(A,B,\pi)$`
2. 对于一个给定的输入`$S$`及其可能的输出序列`$S_w$`,快速的计算`$P(S_w|\mu)$`
3. 快速地选择“最优”的状态序列`$S_w$`（词性序列），使其最好的解释观察序列。所有可能的`$S_w$`中使概率`$P(S_w|\mu)$`最大的解就是要找的分词结果。

~~~~
##### 算法评价
- 优点
	- 可以减少很多手工标注的工作
	- 在训练语料规模足够大和覆盖领域足够多时，可以获得较高的切分正确率
~~~~

- 弱点：
	- 训练语料的规模和覆盖领域不好把握
	- 模型实现复杂、计算量较大

~~~~

#### 5.8.10 基于统计的分词与词性标注一体化方法
~~~~

##### 基本思想
设句子`$S$`由词串组成`$W=w_1w_2…w_n(n\geq1)$`，单词`$w_i$` 的词性标注为`$t_i$`，即句子`$S$`相应的词性标注符号序列可表达为`$T=t_1t_2...t_n$`。那么，分词与词性标注的任务就是要在`$S$`所对应的各种切分和标注形式中，寻找`$T$`和`$W$`的联合概率`$P(W,T)$`为最优的词切分和标注组合。

~~~~
#### 5.8.10 由字构词的(基于字标注)分词方法(Character-based tagging )
~~~~
##### 基本思想
将分词过程看作是字的分类问题。该方法认为，每个字在构造一个特定的词语时都占据着一个确定的构词位置(即词位)。假定每个字只有4个词位：<font color=yellow>词首(B)、词中(M)、词尾(E)和单独成词(S)</font>，那么，每个字归属一特定的词位。
这里所说的“字”不仅限于汉字，也可以指标点符号、外文字母、注音符号和阿拉伯数字等任何可能出现在汉语文本中的文字符号，所有这些字符都是由字构词的基本单元。
~~~~
基于字标注分词方法示例  
- 上海/ 计划/ 到/ 本/ 世纪/ 末/ 实现/ 人均/ 国内/ 生产/ 总值/ 五千美元/ 。/  

- 上/B 海/E 计/B 划/E 到/S 本/S 世/B 纪/E 末/S 实/B 现/E 人/B 均/E 国/B 内/E 生/B 产/E 总/B 值/E 五/B 千/M 美/M 元/E 。/S  
~~~~

在字标注过程中，对所有的字根据预定义的特征进行词位特征学习，获得一个概率模型，然后在待切分字串上，根据字与字之间的结合紧密程度，得到一个词位的分类结果，最后根据词位定义直接获得最终的分词结果。
~~~~

##### 标注方法
1. 支持向量机（SVM）
2. 条件随机场（CRF）

注：最常用的两类特征是字本身和词位(状态)的转移概率
~~~~

##### 算法评价
该方法的重要优势在于，它能够平衡地看待词表词和未登录词的识别问题，文本中的词表词和未登录词都是用统一的字标注过程来实现的。在学习构架上，既可以不必专门强调词表词信息，也不用专门设计特定的未登录词识别模块，因此，大大地简化了分词系统的设计
~~~~

#### 5.8.11 其它方法
1. 串频统计和词形匹配相结合的分词方法
2. 基于有效子串标注的中文分词
3. 规则方法与统计方法相结合
4. 多重扫描法
5. ……
~~~~

#### 5.8.13 方法比较
1. <font color=yellow>最大匹配分词算法</font>是一种简单的基于词表的分词方法，有着非常广泛的应用。这种方法只需要最少的语言资源（仅需要一个词表，不需要任何词法、句法、语义知识），程序实现简单，开发周期短，是一个简单实用的方法，但对歧义字段的处理能力不够强大。
~~~~
2. <font color=yellow>全切分方法</font>首先切分出与词表匹配的所有可能的词，然后运用统计语言模型和决策算法决定最优的切分结果。这种切分方法的优点是可以发现所有的切分歧义，但解决歧义的方法很大程度上取决于统计语言模型的精度和决策算法，需要大量的标注语料，并且分词速度也因搜索空间的增大而有所缓慢。
~~~~

3. <font color=yellow>最短路径分词方法</font>的切分原则是使切分出来的词数最少。这种切分原则多数情况下符合汉语的语言规律，但无法处理例外的情况，而且如果最短路径不止一条时，系统往往不能确定最优解。
~~~~
4. <font color=yellow>统计方法</font>具有较强的歧义区分能力，但需要大规模标注(或预处理) 语料库的支持，需要的系统开销也较大。
~~~~
#### 5.8.13 分词结果评测
~~~~
##### 测试方式
1. 封闭测试/ 开放测试
2. 专项测试/ 总体测试
~~~~
##### 评测指标
1. 正确率(Precision)  
测试结果中正确结果的个数占系统所有输出结果的比例,假设系统输出`$N$`个，其中，正确的结果为`$n$`个
$$
C=\frac{n}{N}
$$
~~~~
2. 召回率(找回率,Recall) 
测试结果中正确结果的个数占标准答案总数的比例。假设系统输出`$N$`个结果,其中，正确的结果为`$n$`个，而标准答案的个数为`$M$`个
$$
R=\frac{n}{M}
$$
~~~~
3. F-测度值(F-Measure): 
正确率与召回率的综合值。计算公式为:
$$
F-measure=\frac{(\beta^2+1)\times C\times R}{\beta^2\times (C\ + R) }
$$

一般情况下，取`$\beta=1$`，即
$$
F=\frac{2\times C\times R}{C+R}
$$
~~~~
### 5.9 词性标注（POS tagging）
词性(part-of-speech, POS)标注(tagging)的主要任务是消除词性兼类歧义。
~~~~
词性标注示例
- 英语句子  
	1. Time flies like an arrow. 
	2. I want you to web our annual report.   
~~~~
汉语中常用词兼类现象严重，《现代汉语八百词》兼类占22.5％。
~~~~

#### 5.9.1 汉语中的词性兼类现象
~~~~
1. 形同音不同
~~~~
- 示例  
好（hǎo，形容词）、好（hào，动词）

这个人什么都好，就是好酗酒。  
~~~~

2. 同形、同音，但意义毫不相干
~~~~
- 示例  
会（会议，名词）、会（能够,动词）

每次他都<font color=yellow>会</font>在<font color=yellow>会</font>上制造点新闻。 
~~~~
3. 具有典型意义的兼类词
~~~~
- 示例  
典型(名词或形容词)、教育(名词或动词)

让孩子接受那样的<font color=yellow>教育</font>简直是对<font color=yellow>教育</font>事业的侮辱。 
~~~~

4. 上述情况的组合
- 示例  
“行（xíng，动词/形容词；háng，名词/量词）”

每当他走过那行白杨树时，他都感觉好像每一棵树都在向他行注目礼。
~~~~

#### 5.9.2 词类自动标注的任务
判定自然语言句子中的每个词的词类并给每个词赋以词类标记。 
~~~~

- 示例  
	- 这份特区政府的报告长达20页。
	- 这/r 份/q 特区/n 政府/n 的/u 报告/n 长/a 达/v 20/m 页/q 。/w

~~~~
对于兼类词，词类标注程序应根据上下文确定兼类词在句子中最合适的词类标记。(难点所在)

~~~~

#### 5.9.3 词性标注集
~~~~
标注集的确定原则：
1. 不同语言中，词性划分基本上已经约定俗成。
2. 自然语言处理中对词性标记要求相对细致。
~~~~

一般原则：
1. 标准性: 普遍使用和认可的分类标准和符号集;
2. 兼容性: 与已有资源标记尽量一致，或可转换；
3. 可扩展性：扩充或修改。
~~~~

UPenn Treebank的词性标注集确定原则
1. 可恢复性(recoverability)：从标注语料能恢复原词汇或借助于句法信息能区分不同词类；
2. 一致性(consistency)：功能相同的词应该属于同一类；
3. 不明确性(indeterminacy)：为了避免标注者在不明确的条件下任意决定标注类型，允许标注者给出多个标记（限于一些特殊情况）。
~~~~

北大计算语言学研究所的词性标注集

规范2001--39个词类标记，用于标注《人民日报》语料库；
~~~~
规范2003

扩充至106个词类标记(26个基本词类代码，74个扩充代码)
名词(n)、时间词(t)、处所词(s)、方位词(f)、数词(m)、量词(q)、区别词(b)、代词(r)、动词(v)、形容词(a)、状态词(z)、副词(d)、介词(p)、连词(c)、助词(u)、语气词(y)、叹词(e)、拟声词(o)、成语(i)、习用语(l)、简称(j)、前接成分(h)、后接成分(k)、语素(g)、非语素字(x)、标点符号(w)。

~~~~

#### 5.9.4 词性标注方法
~~~~

1. 基于规则的词性标注方法
2. 基于统计模型的词性标注方法
3. 规则和统计方法相结合的词性标注方法
4. 基于有限状态变换机的词性标注方法
5. 基于神经网络的词性标注方法
~~~~

设句子`$S$`由词串组成`$W=w_1w_2…w_n(n\geq1)$`，单词`$w_i$`。  
词`$w_i(1\leq i\leq n)$`的词性标注为`$t_i$`，即句子`$S$`相应的词性标注符号序列`$T$`可表达为：
$$
T=t_1,t_2,...,t_n(n\geq 1)
$$
那么，分词与词性标注的任务就是要在`$S$`所对应的各种切分和标注形式中，寻找`$T$`和`$W$`的联合概率`$P(W,T)$`为最优的词切分和标注组合。
~~~~
##### 基于隐马尔科夫模型的词类标注
- HMM状态集(词类标记集)  
- HMM输出符号集(词表)       
- 如何根据观察到的词串(句子)，求解最可能的词类标记序列(状态转换序列)。维特比算法  
- 模型参数  
`$p(t_i|t_{i-1})$`词类转移概率(二元语法模型)
`$p(w_i|t_i)$`词类`$t_i$`生成词`$w_i$`的概率
`$p(t)$`词类`$t$`出现在句首的概率

~~~~
![hmm](../cl/img/hmm.png)

~~~~

##### 参数训练
1. 有指导的学习

训练时需要预先准备带词类标记的语料库，因此在训练时看到了状态（词性），属于VMM，在测试时，只能看到观察值（词序列），因此属于HMM。
~~~~
应用最大似然估计
$$
P(t_i|t_{i-1})=\frac{c(t_{i-1},t_i)}{c(t_{i-1})}
$$
$$
P(w_i|t_i)=\frac{c(t_i,w_i)}{c(t_i)}
$$
~~~~
平滑：  
`$P(w_i|t_i)$`:加1平滑  
`$P(t_i|t_{i-1})$`:线性插值
~~~~
2. 无指导的学习

语料库只是词的序列，没有人工标注词性，是Plain Text。  完全无指导的学习是不可能的,至少要知道：  

<p align="left">(1) 词性集</p>
<p align="left">(2) 每个词可能的词性（根据词典）</p>

<p align="left">例如，使用Baum-Welch算法</p>
~~~~

汉语词类标注实例

- 作为动词的“报告”(30次)
	1. ...５３岁的福塞特向总部报告说，负责热气球...
	2. ...将刘青山、张子善的严重犯罪事实报告党中央，...
	3. ...有关矿产资源情况，要每周向中央主要领导报告。
- 作为名词的“报告”(200次)
	1. ...在党的十五大报告中，江主席再次郑重地...
	2. ...报告认为，虽然日本政府为减少限制性贸易...
	3. ...国际金融协会发表资金流动报告... 

~~~~
问题  
“发生交通事故时，当事人应当迅速报告公安机关，听候处理...”中的“报告”是动词还是名词?
~~~~

![pos1](../cl/img/pos.png)
~~~~
![pos2](../cl/img/pos2.png)